{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction to Content-Based Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collaborative systems discussed in the previous chapters use the correlations in the ratings patterns across users to make recommendations. On the other hand, these methods do not use item attributes for computing predictions.\n",
    "\n",
    "Content-based systems are designed to exploit scenarios in which items can be described with descriptive sets of attributes. In such cases, a userâ€™s own ratings and actions on other movies are sufficient to discover meaningful recommendations. This approach is particularly useful when the item is new, and there are few ratings available for that item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content-based recommender systems try to match users to items that are similar to what they have liked in the past. This similarity is not necessarily based on rating correlations across users but on the basis of the attributes of the objects liked by the user. Unlike collaborative systems, which explicitly leverage the ratings of other users in addition to that of the target user, content-based systems largely focus on the target userâ€™s own ratings and the attributes of the items liked by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content-based systems are dependent on two sources of data:\n",
    "\n",
    "1. Description of various item: <br>\n",
    "   E.g. text description of the item.\n",
    "\n",
    "2. User profile data: <br>\n",
    "   Corresponds to the user feedback of the items (e.g. explicit or implicit). Explicit feedback may correspond to ratings, whereas implicit feedback may correspond to user actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’¡It is noteworthy that the ratings of the other users usually play no role in a content-based recommendation algorithm. This is both an advantage and a disadvantage, depending on the scenario at hand. On the one hand, in cold-start scenarios, where little information about the ratings of other users is available, such an approach can still be used as long as sufficient information about the userâ€™s own interests are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Basic Components of Content-Based Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content-based systems are, therefore, particularly well suited to giving recommendations in text-rich and unstructured domains. The main components of content-based systems include the (offline) preprocessing portion, the (offline) learning portion, and the online prediction portion. The various components of content-based systems are as follows:\n",
    "\n",
    "1. Preprocessing and feature extraction: <br>\n",
    "   Features are extracted from these various sources to convert them into a keyword-based vector-space representation.\n",
    "2. Content-based learning of user profiles: <br>\n",
    "   This stage is often not very different from classification or regression modeling, depending on whether the feedback is categorical (e.g., binary act of selecting an item), or whether the feedback is numerical (e.g., ratings or buying frequency). The resulting model is referred to as the user profile because it conceptually relates user interests (ratings) to item attributes.\n",
    "3. Filtering and recommendation: <br>\n",
    "   In this step, the learned model from the previous step is used to make recommendations on items for specific users. It is important for this step to be very efficient because the predictions need to be performed in real time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Feature Selection and Weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two distinct aspects to incorporating the feature informativeness in the document representation. One is feature selection, which corresponds to the removal of words. The second is feature weighting, which involves giving greater importance to words. Note that stop-word removal and the use of inverse-document frequency are examples of feature selection and weighting, respectively. However, these are unsupervised ways of feature selection and weighting, where user feedback is given no importance. In this section, we will study supervised methods for feature selection, which take the user ratings into account for evaluating feature informativeness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Gini Index**\n",
    "\n",
    "The Gini index is one of the most commonly used measures for feature selection. It is a simple and intuitive measure, which is easy to understand. The Gini index is inherently suited to binary ratings, ordinal ratings, or ratings which are distributed into a small number of intervals.\n",
    "\n",
    "Let $t$ be the total number of possible values of the rating. Among documents containing a particular word $w$, let $p_1(w) \\dots p_t(w)$ be the fraction of the items rated at each of these $t$ possible values. Then, the Gini index of the word $w$ is defined as follows:\n",
    "\n",
    "$$ \\text{Gini}(w) = 1 - \\sum_{i=1}^{t}p_{i}(w)^{2} $$\n",
    "\n",
    "The value of Gini($w$) always lies in the range $(0, 1âˆ’\\frac{1}{t})$, with smaller values being indicative of greater discriminative power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Entropy**\n",
    "\n",
    "As in the previous case, let t be the total number of possible values of the rating and $p_1(w) \\dots p_t(w)$ be the fraction of the documents containing a particular word w, which are rated at each of these t possible values. Then, the entropy of the word w is defined as follows:\n",
    "\n",
    "$$ \\text{Entropy}(w) = - \\sum_{i=1}^{t}p_i(w)log(p_i(w)) $$\n",
    "\n",
    "The value of Entropy($w$) always lies in the range $(0, 1)$, with smaller values being more indicative of discriminative power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Normalized Deviation**\n",
    "\n",
    "The problem with most of the aforementioned measures is that they lose information about the relative ordering of ratings. For cases in which the ratings have high granularity, the normalized deviation is an appropriate measure.\n",
    "\n",
    "Let $Ïƒ^{2}$ be the variance of the ratings in all the documents. Furthermore, let $Î¼^{+}(w)$ be the average rating of all documents containing the word $w$, and $Î¼^{âˆ’}(w)$ be the average rating of all documents that do not contain the word $w$. Then, the normalized deviation of the word $w$ is defined as follows:\n",
    "\n",
    "$$ \\text{Dev}(w) = \\frac{|Î¼^{+}(w) - Î¼^{âˆ’}(w) |}{\\sigma} $$\n",
    "\n",
    "Larger values of Dev($w$) are indicative of more discriminatory words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.1.2 Feature Weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Weighting can be viewed as a soft version of feature selection and is a more refined approach for discriminating between various words by using a weight rather than a hard binary decision. The simplest approach to feature weighting is to take any of the feature selection measures and use them to derive the weights. For example, the inverse of the Gini index or entropy could be used as follows:\n",
    "\n",
    "Consider the following weighting function g($w$) for word $w$, where $a$ is a parameter greater than 1.\n",
    "\n",
    "$$ g(w) = a - \\text{Gini}(w) $$\n",
    "\n",
    "The resulting weight g($w$) will always lie in the range ($a âˆ’ 1, a$). By varying the value of $a$, the sensitivity of the weighting process can be controlled. Smaller values of a will lead to greater sensitivity. The weight of each word $w$ in the vector-space representation is then multiplied by g($w$). Similar weighting functions can be defined with respect to the entropy and the normalized deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training documents correspond to the descriptions of items, which are extracted in the preprocessing and feature selection phases. Furthermore, the training data contain the ratings assigned by the active user to these documents.\n",
    "\n",
    "Note: The training models are specific to particular users, and they cannot be used for arbitrarily chosen users. This is different from traditional collaborative filtering, in which methods like matrix factorization build a single model across all users. The training model for a specific user represents the user profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Nearest Neighbor Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nearest neighbor classifier is one of the simplest classification techniques, and it can be implemented in a relatively straightforward way. The first step is to define a similarity function, which is used in the nearest neighbor classifier. The most commonly used similarity function is the cosine function.\n",
    "\n",
    "Let $X = (x_1 \\dots x_d)$ and $Y = (y_1 \\dots y_d)$ be a pair of documents, in which the normalized frequencies of the ith word are given by $x_i$ and $y_i$, respectively, in the two documents. Note that these frequencies are normalized or weighted with the use of unsupervised tf-idf weighting or the supervised methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosine similarity is frequently used in the text domain because of its ability to adjust to the varying lengths of the underlying documents. When this approach is used for other types of structured and multidimensional data, other similarity/distance functions, such as the Euclidean distance and Manhattan distance, are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{Cosine}(X, Y) = \\frac{\\sum_{i=1}^{d}x_i y_i}{\\sqrt{\\sum_{i=1}^{d}x_{i}^{2}}\\sqrt{\\sum_{i=1}^{d}y_{i}^{2}}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main challenge with the use of this approach is its high computational complexity. One way of making the approach faster is to use clustering to reduce the number of training documents in $D_L$. For each distinct value of the rating, the corresponding subset of documents in $D_L$ are clustered into $p â‰ª |D_L|$ groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayes classifier is discussed in section 3.4 of Chapter 3 in collaborative filtering. However, the discussion in Chapter 3 is a non-standard use of the Bayes model in which the missing entries are predicted from the specified ones. In the context of content-based recommender systems, the problem translates to a more conventional use of the Bayes model for text classification. Therefore, we will revisit the Bayes model in the context of text classification.\n",
    "\n",
    "- **Training and Test Sets**:\n",
    "  - Set $DL$ contains the training documents.\n",
    "  - Set $DU$ contains the test documents.\n",
    "  - Labels are binary: users specify either a like or a dislike rating as $+1$ or $-1$ respectively for each training document in $DL$.\n",
    "\n",
    "- **Binary Ratings**:\n",
    "  - Rating of the $i$th document in $DL$ is denoted by $c_i \\in \\{-1, 1\\}$.\n",
    "  - Two common models for text data: Bernoulli and multinomial models. The Bernoulli model is discussed here.\n",
    "\n",
    "- **Bernoulli Model**:\n",
    "  - Frequencies of words are ignored; only the presence or absence of the word in the document is considered.\n",
    "  - Each document is treated as a binary vector of $d$ words containing values of $0$ and $1$.\n",
    "  - For a target document $X \\in DU$ with binary features $(x_1, ..., x_d)$, we want to determine $P(\\text{Active user likes } X|x_1, ..., x_d)$.\n",
    "\n",
    "- **Bayes Rule and Naive Assumption**:\n",
    "  - If the class (binary rating) of $X$ is denoted by $c(X)$, we determine $P(c(X) = 1|x_1, ..., x_d)$.\n",
    "  - Using Bayes rule:\n",
    "    $$ P(c(X) = 1|x_1, ..., x_d) \\propto P(c(X) = 1) \\cdot P(x_1, ..., x_d|c(X) = 1) = P(c(X) = 1) \\cdot \\prod_{i=1}^d P(x_i|c(X) = 1) $$\n",
    "  - The naive assumption is that the occurrences of words in documents are conditionally independent events on a specific class.\n",
    "\n",
    "- **Proportionality Constant**:\n",
    "  - To rank the propensity of different items (documents) to be liked by the user, the constant of proportionality $K$ is needed.\n",
    "  - Sum of the probabilities of all possible instantiations of $c(X)$ should always be 1:\n",
    "    $$ K \\cdot \\left[ P(c(X) = 1) \\cdot \\prod_{i=1}^d P(x_i|c(X) = 1) + P(c(X) = -1) \\cdot \\prod_{i=1}^d P(x_i|c(X) = -1) \\right] = 1 $$\n",
    "  - Solving for $K$:\n",
    "    $$ K = \\frac{1}{P(c(X) = 1) \\cdot \\prod_{i=1}^d P(x_i|c(X) = 1) + P(c(X) = -1) \\cdot \\prod_{i=1}^d P(x_i|c(X) = -1)} $$\n",
    "\n",
    "- **Ranking Items**:\n",
    "  - This approach is used to determine the probability of a user liking each possible item in $DU$.\n",
    "  - Items in $DU$ are ranked according to this probability and presented to the user.\n",
    "  - These methods are particularly well-suited to binary ratings, but can also be adapted for non-binary ratings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ðŸ’¡An example can be found in the Appendix section at the end of the notebook.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Regression-Based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $D_L$ be an $n \\times d$ matrix representing the $n$ documents in the labeled training set $DL$ on a lexicon of size $d$. Similarly, let $y$ be an $n$-dimensional column vector containing the ratings of the active user for the $n$ documents in the training set. Let $W$ be a $d$-dimensional row vector representing the coefficients of each word in the linear function relating word frequencies to the rating.\n",
    "\n",
    "In order to maximize the quality of the prediction, one must minimize the squared norm of this vector. Furthermore, a regularization term $\\lambda||W||^2$ may be added to the objective function in order to reduce overfitting. This form of regularization is also referred to as Tikhonov regularization.\n",
    "\n",
    "Therefore, the objective function $O$ can be expressed as follows:\n",
    "$$ \\text{Minimize } O = ||D_{L}W^Tâˆ’ y||^2 + \\lambda||W||^2 $$\n",
    "The problem can be solved by setting the gradient of this objective function with respect to $W$ to 0.\n",
    "\n",
    "**Note**: $L1$ (Lasso) can be used but the optimization problem does not have a closed form so Gradient Descent has to be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Explainability of Content-Based Recommenders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since content-based systems extract models based on content features, they often provide highly interpretable insights for the recommendation process. For example, in a movie recommendation system, it is often useful to present the user with a reason as to why they might like a specific movie, such as the presence of a particular genre feature, actor feature, or an informative set of keywords.\n",
    "\n",
    "### Advantages of Content-Based Methods\n",
    "\n",
    "- **New Item Adaptability**:\n",
    "  - Can recommend new items without existing ratings.\n",
    "  - Utilizes previous items rated by a user to make recommendations.\n",
    "  - Addresses cold-start problems for new items, but not new users.\n",
    "  \n",
    "- **Explanatory Power**:\n",
    "  - Provides explanations for recommendations based on item features.\n",
    "  - Collaborative methods often lack this explanatory capability.\n",
    "  \n",
    "- **Ease of Use**:\n",
    "  - Compatible with off-the-shelf text classifiers.\n",
    "  - Requires less engineering effort compared to collaborative systems.\n",
    "  - Each user-specific classification problem is typically smaller.\n",
    "\n",
    "### Disadvantages of Content-Based Methods\n",
    "\n",
    "- **Overspecialization**:\n",
    "  - Tends to recommend items similar to those already seen by the user.\n",
    "  - Lacks novelty and serendipity in recommendations.\n",
    "  - Struggles to recommend items outside the user's existing interests.\n",
    "  \n",
    "- **Cold-Start for New Users**:\n",
    "  - Severe cold-start problem for new users due to insufficient training data.\n",
    "  - Discards training data from other users, leading to potential overfitting.\n",
    "\n",
    "### Complementary Nature\n",
    "\n",
    "- Content-based methods complement collaborative systems well.\n",
    "- Hybrid recommender systems combine both methods to create more robust recommendations.\n",
    "- Content-based systems are rarely used in isolation, often paired with other recommender types for enhanced performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Dataset\n",
    "\n",
    "#### Training Set (\\(DL\\))\n",
    "We have the following training documents and binary ratings (like = +1, dislike = -1):\n",
    "\n",
    "| Keyword   | Drums | Guitar | Beat | Classical | Symphony | Orchestra | Rating  |\n",
    "|-----------|-------|--------|------|-----------|----------|-----------|---------|\n",
    "| Song-1    | 1     | 1      | 1    | 0         | 0        | 0         | Dislike |\n",
    "| Song-2    | 1     | 1      | 0    | 0         | 0        | 1         | Dislike |\n",
    "| Song-3    | 0     | 1      | 1    | 0         | 0        | 0         | Dislike |\n",
    "| Song-4    | 0     | 0      | 0    | 1         | 1        | 1         | Like    |\n",
    "| Song-5    | 0     | 1      | 0    | 1         | 0        | 1         | Like    |\n",
    "| Song-6    | 0     | 0      | 0    | 1         | 1        | 0         | Like    |\n",
    "\n",
    "#### Test Set (\\(DU\\))\n",
    "\n",
    "| Keyword | Drums | Guitar | Beat | Classical | Symphony | Orchestra | Rating |\n",
    "|---------|-------|--------|------|-----------|----------|-----------|--------|\n",
    "| Test-1  | 0     | 0      | 0    | 1         | 0        | 0         | ?      |\n",
    "| Test-2  | 1     | 0      | 1    | 0         | 0        | 0         | ?      |\n",
    "\n",
    "### Step-by-Step Calculation\n",
    "\n",
    "#### Step 1: Calculate Priors\n",
    "Calculate the prior probabilities of each class.\n",
    "\n",
    "- **P(Like)**:\n",
    "  \\[\n",
    "  P(\\text{Like}) = \\frac{3}{6} = 0.5\n",
    "  \\]\n",
    "- **P(Dislike)**:\n",
    "  \\[\n",
    "  P(\\text{Dislike}) = \\frac{3}{6} = 0.5\n",
    "  \\]\n",
    "\n",
    "#### Step 2: Calculate Likelihoods\n",
    "Calculate the likelihood of each word given the class.\n",
    "\n",
    "- **P(word | Like)**:\n",
    "  - Drums: \\(\\frac{0+1}{3+6} = \\frac{1}{9}\\)\n",
    "  - Guitar: \\(\\frac{1+1}{3+6} = \\frac{2}{9}\\)\n",
    "  - Beat: \\(\\frac{0+1}{3+6} = \\frac{1}{9}\\)\n",
    "  - Classical: \\(\\frac{3+1}{3+6} = \\frac{4}{9}\\)\n",
    "  - Symphony: \\(\\frac{2+1}{3+6} = \\frac{3}{9}\\)\n",
    "  - Orchestra: \\(\\frac{2+1}{3+6} = \\frac{3}{9}\\)\n",
    "\n",
    "- **P(word | Dislike)**:\n",
    "  - Drums: \\(\\frac{2+1}{3+6} = \\frac{3}{9}\\)\n",
    "  - Guitar: \\(\\frac{3+1}{3+6} = \\frac{4}{9}\\)\n",
    "  - Beat: \\(\\frac{2+1}{3+6} = \\frac{3}{9}\\)\n",
    "  - Classical: \\(\\frac{0+1}{3+6} = \\frac{1}{9}\\)\n",
    "  - Symphony: \\(\\frac{0+1}{3+6} = \\frac{1}{9}\\)\n",
    "  - Orchestra: \\(\\frac{1+1}{3+6} = \\frac{2}{9}\\)\n",
    "\n",
    "#### Step 3: Apply Bayes' Theorem\n",
    "Calculate the posterior probabilities for the test documents.\n",
    "\n",
    "- **For \\( P(\\text{Like} | \\text{Test-1}) \\)**:\n",
    "  \\[\n",
    "  P(\\text{Like} | \\text{Test-1}) \\propto P(\\text{Like}) \\cdot P(\\text{Classical} = 1 | \\text{Like}) \\cdot P(\\text{Drums} = 0 | \\text{Like}) \\cdot ...\n",
    "  \\]\n",
    "  \\[\n",
    "  P(\\text{Like} | \\text{Test-1}) \\propto 0.5 \\cdot \\frac{4}{9} \\cdot \\left(1 - \\frac{1}{9}\\right) \\cdot \\left(1 - \\frac{2}{9}\\right) \\cdot \\left(1 - \\frac{1}{9}\\right) \\cdot \\left(1 - \\frac{3}{9}\\right) \\cdot \\left(1 - \\frac{3}{9}\\right)\n",
    "  \\]\n",
    "  \\[\n",
    "  \\propto 0.5 \\cdot \\frac{4}{9} \\cdot \\frac{8}{9} \\cdot \\frac{7}{9} \\cdot \\frac{8}{9} \\cdot \\frac{6}{9} \\cdot \\frac{6}{9} \\approx 0.5 \\cdot 0.01032 \\approx 0.00516\n",
    "  \\]\n",
    "\n",
    "- **For \\( P(\\text{Dislike} | \\text{Test-1}) \\)**:\n",
    "  \\[\n",
    "  P(\\text{Dislike} | \\text{Test-1}) \\propto P(\\text{Dislike}) \\cdot P(\\text{Classical} = 1 | \\text{Dislike}) \\cdot P(\\text{Drums} = 0 | \\text{Dislike}) \\cdot ...\n",
    "  \\]\n",
    "  \\[\n",
    "  P(\\text{Dislike} | \\text{Test-1}) \\propto 0.5 \\cdot \\frac{1}{9} \\cdot \\left(1 - \\frac{3}{9}\\right) \\cdot \\left(1 - \\frac{4}{9}\\right) \\cdot \\left(1 - \\frac{3}{9}\\right) \\cdot \\left(1 - \\frac{1}{9}\\right) \\cdot \\left(1 - \\frac{2}{9}\\right)\n",
    "  \\]\n",
    "  \\[\n",
    "  \\propto 0.5 \\cdot \\frac{1}{9} \\cdot \\frac{6}{9} \\cdot \\frac{5}{9} \\cdot \\frac{6}{9} \\cdot \\frac{8}{9} \\cdot \\frac{7}{9} \\approx 0.5 \\cdot 0.00741 \\approx 0.00371\n",
    "  \\]\n",
    "\n",
    "Since \\( P(\\text{Like} | \\text{Test-1}) > P(\\text{Dislike} | \\text{Test-1}) \\), the classifier predicts \"Like\" for Test-1.\n",
    "\n",
    "- **For \\( P(\\text{Like} | \\text{Test-2}) \\)**:\n",
    "  \\[\n",
    "  P(\\text{Like} | \\text{Test-2}) \\propto 0.5 \\cdot P(\\text{Drums} = 1 | \\text{Like}) \\cdot P(\\text{Beat} = 1 | \\text{Like}) \\cdot P(\\text{Guitar} = 0 | \\text{Like}) \\cdot ...\n",
    "  \\]\n",
    "  \\[\n",
    "  P(\\text{Like} | \\text{Test-2}) \\propto 0.5 \\cdot \\frac{1}{9} \\cdot \\frac{1}{9} \\cdot \\left(1 - \\frac{2}{9}\\right) \\cdot \\left(1 - \\frac{4}{9}\\right) \\cdot \\left(1 - \\frac{3}{9}\\right) \\cdot \\left(1 - \\frac{3}{9}\\right)\n",
    "  \\]\n",
    "  \\[\n",
    "  \\propto 0.5 \\cdot \\frac{1}{9} \\cdot \\frac{1}{9} \\cdot \\frac{7}{9} \\cdot \\frac{5}{9} \\cdot \\frac{6}{9} \\cdot \\frac{6}{9} \\approx 0.5 \\cdot 0.00216 \\approx 0.00108\n",
    "  \\]\n",
    "\n",
    "- **For \\( P(\\text{Dislike} | \\text{Test-2}) \\)**:\n",
    "  \\[\n",
    "  P(\\text{Dislike} | \\text{Test-2}) \\propto 0.5 \\cdot P(\\text{Drums} = 1 | \\text{Dislike}) \\cdot P(\\text{Beat} = 1 | \\text{Dislike}) \\cdot P(\\text{Guitar} = 0 | \\text{Dislike}) \\cdot ...\n",
    "  \\]\n",
    "  \\[\n",
    "  P(\\text{Dislike} | \\text{Test-2}) \\propto 0.5 \\cdot \\frac{3}{9} \\cdot \\frac{3}{9} \\cdot \\left(1 - \\frac{4}{9}\\right) \\cdot \\left(1 - \\frac{1}{9}\\right) \\cdot \\left(1 - \\frac{1}{9}\\right) \\cdot \\left(1 - \\frac{2}{9}\\right)\n",
    "  \\]\n",
    "  \\[\n",
    "  \\propto 0.5 \\cdot \\frac{3}{9} \\cdot \\frac{3}{9} \\cdot \\frac{5}{9} \\cdot \\frac{8}{9} \\cdot \\frac{8}{9} \\cdot \\frac{7}{9} \\approx 0.5 \\cdot 0.03197 \\approx 0.01598\n",
    "  \\]\n",
    "\n",
    "Since \\( P(\\text{Dislike} | \\text{Test-2}) > P(\\text{Like} | \\text{Test-2}) \\), the classifier predicts \"Dislike\" for Test-2.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Test-1** is predicted to be **Like**.\n",
    "- **Test-2** is predicted to be **Dislike**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
