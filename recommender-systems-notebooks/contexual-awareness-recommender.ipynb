{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Context-Sensitive Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "_“For me context is the key – from that comes the understanding of everything.”– Kenneth Noland_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Context-sensitive recommender systems** tailor their recommendations to additional information that defines the specific situation under which recommendations are made. This additional information is referred to as the *context*.\n",
    "\n",
    "1. **Time:** Recommendations can be affected by many aspects of time, such as weekdays, weekends, holidays, and so on. A recommendation that is relevant to the morning context, may not be relevant in the evening and vice versa.\n",
    "\n",
    "2. **Location:** With the increasing popularity of GPS-enabled mobile phones, location-sensitive recommendations have gained increasing importance in recent years. For example, a traveling user might wish to determine a recommendation for a restaurant in their locality. Context-sensitive systems can provide more relevant recommendations by using the location as a context.\n",
    "\n",
    "3. **Social information:** The social context is often important from the perspective of recommender systems. For example, the choice of a user’s friends, tags, and social circles can affect the recommendation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "In traditional recommender systems with user set $U$ and item set $I$, the set of possibilities in $U × I$ is mapped to a rating. This mapping results in (an incompletely specified) ratings matrix of size $|U|×|I|$. In a context-aware system, an additional set of contextual possibilities is present in a set $C$. For example, the set $C$ might be {morning, afternoon, night}, with the context corresponding to the time of day. In this case, it is no longer possible to map the possibilities in $U × I$ to the ratings, because the same user might have different preferences for an item depending on whether the time is in the morning, afternoon, or night.\n",
    "\n",
    "Therefore, in context-sensitive recommender systems, the possibilities in $U × I × C$ are mapped to the ratings. Formally, the function $h_R$, which maps the user, items,\n",
    "and context to the rating, can be written as follows:\n",
    "$$ h_R : U × I × C → \\text{rating} $$\n",
    "\n",
    "The function $h_{R}$ is subscripted with $R$ to denote the data set to which it is applied. In this case, the ratings data $R$ is a 3-dimensional ratings data cube corresponding to the user, item, and context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. The Multi-dimensional Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "* **Traditional Recommenders (2D):** <br>\n",
    "The traditional problem of recommendations can be viewed as that of learning a mapping function from the user-item combinations to the ratings. The corresponding function $f_R$ may be defined as follows:\n",
    "$$f_R : U × I → \\text{rating}$$\n",
    "\n",
    "* **Generalised Recommenders (Multi-dimensional):** <br>\n",
    "This general principle motivates the multi-dimensional approach to recommendations, in which the rating problem is seen as that of mapping a set of $w$ different dimensional values to a rating.\n",
    "$$ g_R : D_1 × D_2 . . . × D_w ⇒ \\text{rating} $$\n",
    "\n",
    "In this case, the ratings data $R$ contain $w$ different dimensions that are mapped to ratings, just as the 2-dimensional user-item combinations are mapped to ratings in the traditional setting. This results in a $w$-dimensional cube rather than a 2-dimensional matrix. The $w$ different dimensions are denoted by $D_1 . . .D_w$.\n",
    "\n",
    "**Note:** Two of these dimensions will always be users and items and some others might be time, location and so on.\n",
    "\n",
    "_Therefore, the traditional recommendation problem can be viewed as a special case of the multi-dimensional approach in which the only two dimensions are users and items._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of Contextual Movie Recommender (using Time):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "![Contextual Cube](img/contextual_cube.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The rating function $g_R$ is defined as a partial* function, in which the number of arguments is equal to the number of dimensions $w$ (e.g. 3 dimensions = {user, item, time}). In the example above, the rating function $g_R$ (David, Terminator, 9 PM) refers to the rating of user David when he watches the movie Terminator at 9 PM.\n",
    "\n",
    "*mapping function $g_R$ is referred to as partial because it is defined only for the subset of cells corresponding to observed rating values. The remaining values need to be learned in a data-driven manner for making contextual recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Problem Statement:** <br>\n",
    " _Determine the top-k possibilities in the “what” (to recommend) dimensions for a particular set of specified values in the “for whom” dimensions._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Definition (Multi-dimensional Recommendations):** <br>\n",
    "Given the recommendation space $D_1 × D_2 × . . . D_w$ and the rating function $g_R$: $D_1 × D_2 . . . × D_w → rating$, the recommendation problem is defined by selecting certain “what” dimensions $D_{i1} . . . D_{ip}$ and certain “for whom” dimensions $D_{j1} . . . D_{jq}$ that do not overlap, and recommending for a query tuple $(d_{j1} . . . d_{jq}) ∈ D_{j1} ×. . .× D_{jq} $ the top-k tuples $(d_{i1} . . . d_{ip}) ∈ D_{i1} ×. . .× D_{ip}$ with the maximum predicted value of the rating $g_R(d_1, d_2, . . . , d_w)$.\n",
    "\n",
    "In other words, a ranked list of the “what” dimension combinations are recommended in response to “for whom” queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Note:** Dimensions such as time can be represented in various granular levels of hierarchy, such as hours, days, weeks, months, and so on. Clearly, the user needs to make careful choices up front about the hierarchy to use, so that the most relevant analysis may be performed in a given application. It is also important to select the most relevant contextual dimensions $D_1 . . . D_w$ for the application at hand. This problem is closely related to that of feature selection in the traditional classification and machine learning literature. Alternatively, these dimensions can be selected by domain experts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Contexual Taxonomy](img/contexual_taxonomy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these hierarchies, one can now make more general (aggregated) queries, such as $g_R\\text{(David, Terminator, Evening)}$, instead of $g_R\\text{(David, Terminator, 7 PM)}$. The former provides an **average** **prediction** of how much David likes the movie Terminator, if he watches it at any time in the evening, whereas the latter provides a prediction of how much he would like it, if he saw the movie in the 7 PM show."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Multi-level Multi-dimensional Rating Estimation Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an initial set of user-assigned ratings specified at different levels of the multi-dimensional cube of ratings, the task is to estimate all other ratings in the cube at all the levels of the OLAP hierarchies.\n",
    "\n",
    "The techniques for performing contextual recommendation fall into one of three categories:\n",
    "\n",
    "**1. Contextual pre-filtering:** <br> \n",
    "In these methods, a segment of the ratings is pre-filtered corresponding to the relevant context. This relevant segment of ratings is then used to make targeted recommendations.\n",
    "\n",
    "**2. Contextual post-filtering:** <br>\n",
    "In these methods, the recommendations are first performed on the entire global set of ratings. Subsequently, the ranked recommendation lists are filtered or adjusted as a post-processing step with the use of temporal context.\n",
    "\n",
    "**3. Contextual modeling:** <br>\n",
    "In this case, the contextual information is incorporated directly into the prediction function, rather than as a pre-filtering or post-filtering step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Contextual **Pre-Filtering** Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contextual pre-filtering** is also referred to as _reduction_ . In the reduction-based approach, the idea is to reduce the $w$-dimensional estimation problem to a set of 2-dimensional estimations. The 2-dimensional estimation problem is equivalent to that in traditional collaborative filtering systems.\n",
    "\n",
    "Consider the case where the three attributes are **users (U)**, **movie items (I)**, and **time (T)**. In such a case, the rating function $g_R$ is defined as follows:\n",
    "$$ g_R : U × I × T → \\text{rating} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3-dimensional ratings estimation can be systematically **reduced to 2-dimensional ratings estimation** on this slice with the following relationship between the 3-dimensional function $g_R$ and the traditional 2-dimensional collaborative filtering function $f_R'(t)$:\n",
    "$$∀(u, i, t) ∈ U × I × T, g_{R}(u, i, t) = f_{R'(t)}(u, i)$$\n",
    "\n",
    "The matrix $R'(t)$ is obtained by first selecting the ratings in which the time is fixed to $t$, and then projecting down to the user and item dimensions. In other words, the 2-dimensional slice of the data cube in which the time is fixed to $t$ corresponds to $R'(t)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Contexual Slicing](img/contextual_slicing.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because only a small subset of the ratings are used in a given slice, one may sometimes not have sufficient ratings to perform an accurate recommendation. In such cases, one may aggregate the rating at $t$ with other adjacent time slices to create more accurate recommendations. For example, instead of using $t = 9$ PM, one might use all values of $t$ in the evening, from 7 PM to 11 PM, and then average the ratings in these slices to create the resulting matrix. The 2-dimensional recommender is then applied to this averaged slice.\n",
    "\n",
    "The **main advantage** of the approach is that it performs the collaborative filtering only over the relevant ratings in which the ratings have been selected with the use of the context. This can lead to improved accuracy in many cases, although the trade-off is that fewer ratings are now being used for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Contextual **Post-Filtering** Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **post-filtering**, the filtering steps are applied to the output obtained *after* applying a global collaborative filtering algorithm that ignores the contextual information in the data set. In other words, in post-filtering methods, the contextual information is ignored, and a global 2- dimensional ratings matrix is created by aggregating the ratings over all the possible contextual values.\n",
    "\n",
    "Therefore, the approach comprises two steps:\n",
    "1. Recommendations are generated on all the data by applying a conventional collaborative filtering model on an _**aggregated**_ user-item matrix. Thus, context is ignored in the first step.\n",
    "\n",
    "2. Context is then used to **adjust** or **filter** the recommended list.\n",
    "\n",
    "The multi-dimensional ratings cube aggregates into a 2-dimensional ratings matrix as follows:\n",
    "* **Explicit ratings:** the aggregation process refers to the averaging of (observed)\n",
    "ratings.\n",
    "\n",
    "* **Implicit feedback:** matrices (e.g., units sold), the process of aggregation refers to the sum of the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when applying traditional collaborative filtering algorithms to this aggregated matrix in order to create predicted ratings $\\hat{r}_{uj}$ and a corresponding ranked list of items for each user $u$, the ranked list is not sensitive to the contextual information, because the contextual dimension was ignored in the recommendation process. The post-filtering strategy adjusts the results after the estimations have been made. The adjustments can be made in one of two different ways:\n",
    "\n",
    "1. Filtering out irrelevant items using heuristic methods.\n",
    "2. Adjusting the ranking of the recommendations in the list based on the underlying context.\n",
    "\n",
    "The latter approach can be viewed as a soft version of the former. Both forms of post-filtering **adjust the predicted rating** $\\hat{r}_{uj}$ for a given user-item combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Filtering Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, The idea behind post-filtering is straightforward – we produce the predicted ratings or the list of top-$N$ items without considering contexts by the traditional recommendation algorithms. Then, we can remove the items that are irrelevant to the contexts.\n",
    "\n",
    "Panniello, et al. (Panniello et al. 2009) proposed the first post-filtering method which can be described as:\n",
    "$$ \n",
    "\\hat{r}(u, i, c) = \n",
    "\\begin{cases} \n",
    "\\hat{r}(u, i) & \\text{if } Pr(u, i, c) \\geq p \\\\ \n",
    "0 & \\text{if } Pr(u, i, c) < p \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "for user ($u$), item ($i$) and context ($c$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The $\\hat{r}(u, i, c)$ refers to the predicted rating for the user $u$ on item $i$ within context situation $c$.\n",
    "* The $\\hat{r}(u, i)$ is the predicted rating without considering contexts by a traditional recommendation algorithm. \n",
    "* The $Pr(u, i, c)$ is an additional calculated probability, with which the user will choose a certain type of item in a given context.\n",
    "\n",
    "This probability is computed as the number of neighbors (i.e., users similar to $u$) who purchased or consumed the same item $i$ in contexts $c$ divided by the number of the total number of neighbors. Using movies as an example,\n",
    "\n",
    "$$\n",
    "Pr(u, i, c) = \\frac{\\text{Number of neighbors who watched movie } i \\text{ in context } c}{\\text{Total number of neighbors}}\n",
    "$$\n",
    "\n",
    "* The $p$ is the minimum threshold to be selected. In real-world settings, $p$ is defined with empirical analysis, business knowledge, A/B testing or by optimising for specific (business) metrics. The choice of $p$ is ultimately a balance between relevance (ensuring the user sees items they’re likely to engage with) and exploration (introducing variety). \n",
    "\n",
    "We set $\\text{r}(u, i, c)$ as zero if this probability is smaller than the threshold $p$, to indicate that the item $i$ is not qualified to be recommended. Otherwise, the model will use $\\hat{r}(u, i)$ to represent $\\hat{r}(u, i, c)$.\n",
    "\n",
    "This method is only valid for evaluating the top-$N$ recommendations as it removes irrelevant items associated with the contexts, since they mark  $R(u, i, c)$ as zero if item $i$ is not appropriate to be recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Adjusting Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramirez, et al. (Ramirez-Garcia and Garca-Valdez 2014) made the second attempt and they proposed a post-filtering method by adjusting the predicted ratings.\n",
    "\n",
    "The predicted rating of a user $u$ for item $i$ in context $c$ is defined as follows:\n",
    "$$\n",
    "\\hat{r}(u, i, c) = \\beta \\cdot \\hat{r}(u, i) + (1 - \\beta) \\cdot \\overline{r}(i, c)\n",
    "$$\n",
    "\n",
    "* The $\\overline{r}(i, c)$ denotes the average value of the ratings that are placed on item $i$ without context $c$.\n",
    "* The $\\hat{r}(u, i)$ is the predicted rating without considering contexts by a traditional recommendation algorithm (e.g. collaborative filtering). \n",
    "* The $\\beta$ parameter is a ratio parameter $(0 < \\beta < 1)$ to control the contribution of each part.\n",
    "\n",
    "The parameter $\\beta$ can be selected similarly as the parameter $p$ in the filtering method above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proposed method above adjusts the predicted ratings compared to the filtering method which filters items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As a summary, to \"adjust\" the ratings based on context, a model can be built that predicts the probability $Pr(u, i, c)$ that **user** $u$ will find **item** $i$ relevant within **context** $c$, where this probability represents how well the item fits the context, helping us rank it more appropriately.\n",
    "\n",
    "$$\n",
    "\\text{Adjusted rating} = Pr(u, i, c) \\cdot \\hat{r}_{ui}\n",
    "$$\n",
    "\n",
    "- This probability can be estimated using various techniques, including:\n",
    "  - **Content-based models** that focus on item attributes.\n",
    "  - **Collaborative filtering with pre-filtering** that narrows down recommendations based on context-specific data.\n",
    "To adjust the ranking based on context, we combine this rating $\\hat{r}_{ui}$ with the context-based probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another post filtering method using rating deviations can be found [here](https://cdn.aaai.org/ocs/17661/17661-77652-1-PB.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Post-filtering can be more robust than pre-filtering in a larger number of situations because one combines the local information $Pr(u, i, c)$ with the rating $\\hat{r}_{ui}$ determined using all the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Contextual Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both pre-filtering and post-filtering, the collaborative filtering problem is reduced to the 2-dimensional setting, and the context is used during pre-processing or post-processing. The **main disadvantage** of this approach is that context is not integrated very tightly into the recommendation algorithm. It is possible to incorporate context directly into the recommendation process by modifying existing models (such as neighborhood-based methods) to the $w$-dimensional setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Neighborhood-Based Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we are interested in predicting the ratings in a 3-dimensional space where the axes represent **users**, **items**, and **context** (e.g., **time**). <br>\n",
    "A point within this 3D cube could be denoted as $A = (u, i, t)$:\n",
    "\n",
    "We define the predicted rating as following:\n",
    "$$\n",
    "\\text{Predicted Rating} = \\frac{\\sum_{k=1}^{r} \\left(\\text{Rating of } B_k \\cdot \\frac{1}{Dist(A, B_k)}\\right)}{\\sum_{k=1}^{r} \\frac{1}{Dist(A, B_k)}}\n",
    "$$\n",
    "\n",
    "where $B_k$ is each of the closest neighbors, and $\\frac{1}{Dist(A, B_k)}$ is the weight for each neighbor $B_k$.\n",
    "\n",
    "1. **Calculation of Distances: $Dist(A, B)$** <br>\n",
    "\n",
    "Consider two points in the 3-dimensional cube, corresponding to $A = (u, i, t)$ and $B = (u', i', t')$ respectively. Then, the distance between $A$ and $B$ can be defined as the sum of the weighted distances (or weighted Euclidean metric alternatively) between the individual dimensions. Using a weighted average rather than a typical Euclidean distance is essential in contextual recommender systems because different dimensions—like user, item, and time—don’t always contribute equally to predicting preferences. Weights allow the model to adapt to the importance of each dimension, which is often context-dependent and can vary across use cases.\n",
    "\n",
    "* **Weighted Distances:** <br>\n",
    "$Dist(A,B) = w_1 · Dist(u, u') + w_2 · Dist(i, i') + w_3 · Dist(t, t)$\n",
    "\n",
    "* **Euclidean weighted Distances:** <br>\n",
    "$Dist(A,B) = \\sqrt{w_1 · Dist(u, u')^2 + w_2 · Dist(i, i')^2 + w_3 · Dist(t, t')^2}$\n",
    "\n",
    "where:\n",
    "- $w_1$, $w_2$, and $w_3$ are the weights for the user, item, and time dimensions, respectively.\n",
    "- $Dist(u, u')$, $Dist(i, i')$, and $Dist(t, t')$ are individual distances for each dimension.\n",
    "\n",
    "\n",
    "2. **Calculation of Distances: $Dist(u, u')$, $Dist(i, i')$, $Dist(t, t)$** <br>\n",
    "\n",
    "There are different ways to calculate the distances. The following are some of the techniques that can be used:\n",
    "- **Collaborative:** In this case, one can use the Pearson method or the adjusted cosine to calculate $Dist(u, u')$, $Dist(i, i')$, $Dist(t, t)$.\n",
    "- **Content-based:** In this case, the attributes associated with the dimensions (i.e., user profiles and item profiles) are used to compute the profile.\n",
    "- **Combined:** It is possible to combine the collaborative and content-based measures to obtain a more robust measure of similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Calculation of Weights: $w_1$, $w_2$, $w_3$** <br>\n",
    "\n",
    "1. **Domain Expertise**: Initial weights can be set based on domain knowledge if a dimension is known to be particularly influential.\n",
    "2. **Hyperparameter Tuning**: Using techniques like grid search to test different weight combinations on a validation set.\n",
    "3. **Learning from Data**: Certain models can learn the weights directly as trainable parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Example Calculation\n",
    "\n",
    "Assume:\n",
    "- $Dist(u, u') = 0.3$,\n",
    "- $Dist(i, i') = 0.5$,\n",
    "- $Dist(t, t') = 0.2$,\n",
    "and weights:\n",
    "- $w_1 = 0.4$,\n",
    "- $w_2 = 0.3$,\n",
    "- $w_3 = 0.3$.\n",
    "\n",
    "**Weighted Euclidean Distance**\n",
    "$$\n",
    "Dist(A, B) = \\sqrt{0.4 \\cdot 0.3^2 + 0.3 \\cdot 0.5^2 + 0.3 \\cdot 0.2^2} = \\sqrt{0.036 + 0.075 + 0.012} \\approx 0.35\n",
    "$$\n",
    "\n",
    "**Predicted Rating (using 3 closest neighbors)**\n",
    "Assume ratings for the 3 closest neighbors $B_1$, $B_2$, and $B_3$ are 4.0, 3.0, and 5.0, with distances:\n",
    "- $Dist(A, B_1) = 0.5$,\n",
    "- $Dist(A, B_2) = 0.3$,\n",
    "- $Dist(A, B_3) = 0.2$.\n",
    "\n",
    "1. **Compute Weights**:\n",
    "   - Weight for $B_1 = \\frac{1}{0.5} = 2$,\n",
    "   - Weight for $B_2 = \\frac{1}{0.3} \\approx 3.33$,\n",
    "   - Weight for $B_3 = \\frac{1}{0.2} = 5$.\n",
    "\n",
    "2. **Weighted Average**:\n",
    "   $$\n",
    "   \\text{Predicted Rating} = \\frac{4.0 \\times 2 + 3.0 \\times 3.33 + 5.0 \\times 5}{2 + 3.33 + 5} \\approx \\frac{8 + 9.99 + 25}{10.33} \\approx 4.13\n",
    "   $$\n",
    "\n",
    "Thus, the predicted rating for $A$ is approximately 4.13.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Factorisation Machines with Contextual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In factorization machines, the basic idea is to **model each rating as a linear combination of interactions between input variables**. The input variables are derived from the original ratings matrix.\n",
    "\n",
    "For example, consider the case in which we have a 3-dimensional cube containing $m$ users, $n$ items, and $d$ values of the contextual dimension, and each rating is associated with a unique triplet. One can then “flatten” this 3-dimensional cube into a set of ($m + n + d$)-dimensional rows, such that each row corresponds to the user, item, and contextual value of an observed rating. Therefore, there are as many rows as the number of observed ratings. We represent the variables of the row by $x_1 . . . x_{m+n+d}$, all of which are either $0s$ or $1s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Contexual Factorization Machines](img/contextual_factorization_machines.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** At first sight, it would seem that we could use a classification or regression predictor on this flattened representation in a straightforward way; however, it would not work very well because of the extraordinary data sparsity, in which there are only three nonzero entries in each row. It is here that factorization machines rescue us from the perils of sparsity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Factorisation Machines (FM)** model formulates rating prediction as a regression problem in which user, item, and additional contextual information are combined into a feature vector $\\mathbf{x}_i$.  The predictor consists of global bias, first-order, and second-order interactions of the input features.  The estimation is as follow:\n",
    "\n",
    "$$\n",
    "\\hat{y}(\\mathbf{x}_i) = w_0 + \\sum_{f=1}^{p} w_f . x_{if} + \\sum_{f=1}^{p} \\sum_{g=f+1}^{p} x_{if} . x_{ig} \\Big( \\sum_{k=1}^{K} v_{fk} . v_{gk} \\Big)\n",
    "$$\n",
    "\n",
    "where $p=(m+n+d)$ is the length of feature vectors and $K$ is the dimensionality of second-order latent factors.\n",
    "\n",
    "The variables to be learned are:\n",
    "1. $w_0$ = Global Bias Variable\n",
    "2. $w_f$ = Feature Covariates\n",
    "3. $v_i$ = Latent Vectors\n",
    "\n",
    "Without the additional features and with only user and item, second-order FM is reduced to matrix factorization.  Therefore, FM is a general framework to incorporate contextual information while maintaining the effectiveness of factorization models in recommender systems.\n",
    "\n",
    "**Note:** FM can be extended and generalized into higher-order interactions.  Given the degree of data sparsity commonly faced in recommender systems, second-order FM is usually sufficient. Higher orders would be less efficient and harder to estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To learn the parameters of the FM regressor, we minimize the following regularized squared loss function using Stohastic Gradient Descent (SGD):\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{w, V} | \\lambda) = \\frac{1}{2} \\sum_{(\\mathbf{x}, y) \\in \\mathcal{D}} (y - \\hat{y}(\\mathbf{x})) + \\frac{\\lambda}{2} || \\mathbf{w} ||^2 + \\frac{\\lambda}{2} ||\\mathbf{V}||_2^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atawua/Documents/03-DATA-SCIENCE/01-github/movielens-100k-recommender-systems/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cornac version: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "# Import common python libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cornac is a python library to implement non-contextual recommenders (used for comparison)\n",
    "import cornac\n",
    "from cornac.utils import cache\n",
    "\n",
    "print(f\"Cornac version: {cornac.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'libfm'...\n",
      "remote: Enumerating objects: 233, done.\u001b[K\n",
      "remote: Total 233 (delta 0), reused 0 (delta 0), pack-reused 233 (from 1)\u001b[K\n",
      "Receiving objects: 100% (233/233), 129.46 KiB | 940.00 KiB/s, done.\n",
      "Resolving deltas: 100% (112/112), done.\n",
      "cd src/libfm; make all\n",
      "g++ -O3 -Wall -c libfm.cpp -o libfm.o\n",
      "In file included from libfm.cpp:57:\n",
      "In file included from ./src/fm_learn_mcmc_simultaneous.h:43:\n",
      "\u001b[1m./src/fm_learn_mcmc.h:739:8: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1mvariable 'num_all' set but not used [-Wunused-but-set-variable]\u001b[0m\n",
      "  739 |   uint num_all = 0;\u001b[0m\n",
      "      | \u001b[0;1;32m       ^\n",
      "\u001b[0m\u001b[1m./src/fm_learn_mcmc.h:854:8: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1mvariable 'num_all' set but not used [-Wunused-but-set-variable]\u001b[0m\n",
      "  854 |   uint num_all = 0;\u001b[0m\n",
      "      | \u001b[0;1;32m       ^\n",
      "\u001b[0m2 warnings generated.\n",
      "mkdir -p ../../bin/\n",
      "g++ -O3 -Wall libfm.o -o ../../bin/libFM\n",
      "g++ -O3 -Wall -c tools/transpose.cpp -o tools/transpose.o\n",
      "mkdir -p ../../bin/\n",
      "g++ -O3 tools/transpose.o -o ../../bin/transpose\n",
      "g++ -O3 -Wall -c tools/convert.cpp -o tools/convert.o\n",
      "mkdir -p ../../bin/\n",
      "g++ -O3 tools/convert.o -o ../../bin/convert\n"
     ]
    }
   ],
   "source": [
    "# Install libfm library needed to train a contextual awareness model\n",
    "!git clone https://github.com/srendle/libfm.git\n",
    "!make all -C libfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from http://files.grouplens.org/datasets/hetrec2011/hetrec2011-movielens-2k-v2.zip\n",
      "will be cached into /Users/atawua/.cornac/hetrec2011-movielens-2k-v2.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18.9MB [00:01, 10.1MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping ...\n",
      "File cached!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/atawua/.cornac/hetrec2011-movielens-2k-v2.zip'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cache the data\n",
    "cache(\"http://files.grouplens.org/datasets/hetrec2011/hetrec2011-movielens-2k-v2.zip\", unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/atawua/.cornac/user_ratedmovies.dat'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the data directory path\n",
    "DATA_DIRECTORY =  \"/Users/atawua/.cornac\"\n",
    "DATA_FILE = \"/user_ratedmovies.dat\"\n",
    "\n",
    "DATA_PATH = DATA_DIRECTORY + DATA_FILE\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>date_day</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_year</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>date_minute</th>\n",
       "      <th>date_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>32</td>\n",
       "      <td>4.5</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>160</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>163</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating  date_day  date_month  date_year  date_hour  \\\n",
       "0      75        3     1.0        29          10       2006         23   \n",
       "1      75       32     4.5        29          10       2006         23   \n",
       "2      75      110     4.0        29          10       2006         23   \n",
       "3      75      160     2.0        29          10       2006         23   \n",
       "4      75      163     4.0        29          10       2006         23   \n",
       "\n",
       "   date_minute  date_second  \n",
       "0           17           16  \n",
       "1           23           44  \n",
       "2           30            8  \n",
       "3           16           52  \n",
       "4           29           30  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data and get a quick view of it\n",
    "user_ratedmovies_df = pd.read_csv(DATA_PATH, sep=\"\\t\")\n",
    "user_ratedmovies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 2113\n",
      "Number of movies: 10109\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_number_of_rated_movies</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6757</th>\n",
       "      <td>3410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30687</th>\n",
       "      <td>2908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30500</th>\n",
       "      <td>2823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62332</th>\n",
       "      <td>2763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51033</th>\n",
       "      <td>2631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54250</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48803</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26873</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28180</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2113 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        total_number_of_rated_movies\n",
       "userID                              \n",
       "6757                            3410\n",
       "30687                           2908\n",
       "30500                           2823\n",
       "62332                           2763\n",
       "51033                           2631\n",
       "...                              ...\n",
       "54250                             20\n",
       "48803                             20\n",
       "26873                             20\n",
       "28180                             20\n",
       "59995                             20\n",
       "\n",
       "[2113 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show data statistics\n",
    "print(\"Number of users:\", user_ratedmovies_df[\"userID\"].nunique())\n",
    "print(\"Number of movies:\", user_ratedmovies_df[\"movieID\"].nunique())\n",
    "\n",
    "(\n",
    "user_ratedmovies_df\n",
    "    .groupby('userID')\n",
    "    .agg({'movieID': 'count'})\n",
    "    .rename({\"movieID\": \"total_number_of_rated_movies\"}, axis=1)\n",
    "    .sort_values(by='total_number_of_rated_movies', ascending=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17084</th>\n",
       "      <td>1860</td>\n",
       "      <td>2893</td>\n",
       "      <td>16</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158426</th>\n",
       "      <td>13283</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555826</th>\n",
       "      <td>44287</td>\n",
       "      <td>2273</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608059</th>\n",
       "      <td>49879</td>\n",
       "      <td>1226</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639291</th>\n",
       "      <td>51954</td>\n",
       "      <td>597</td>\n",
       "      <td>12</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userID  movieID  date_hour  rating\n",
       "17084     1860     2893         16     3.0\n",
       "158426   13283     1234          2     3.5\n",
       "555826   44287     2273          1     3.0\n",
       "608059   49879     1226          8     3.0\n",
       "639291   51954      597         12     2.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a sample of the data (300K) for quicker runs\n",
    "df = user_ratedmovies_df[[\"userID\", \"movieID\", \"date_hour\", \"rating\"]].sample(n=300_000).copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 240000\n",
      "Test size: 60000\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets for evaluation\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "print(\"Training size:\", len(train_df))\n",
    "print(\"Test size:\", len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Factorized Machines with Context (time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>userID_75</th>\n",
       "      <th>userID_78</th>\n",
       "      <th>userID_127</th>\n",
       "      <th>userID_170</th>\n",
       "      <th>userID_175</th>\n",
       "      <th>userID_190</th>\n",
       "      <th>userID_267</th>\n",
       "      <th>userID_325</th>\n",
       "      <th>userID_383</th>\n",
       "      <th>...</th>\n",
       "      <th>date_hour_14</th>\n",
       "      <th>date_hour_15</th>\n",
       "      <th>date_hour_16</th>\n",
       "      <th>date_hour_17</th>\n",
       "      <th>date_hour_18</th>\n",
       "      <th>date_hour_19</th>\n",
       "      <th>date_hour_20</th>\n",
       "      <th>date_hour_21</th>\n",
       "      <th>date_hour_22</th>\n",
       "      <th>date_hour_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>266989</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158068</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552454</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658846</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432255</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating  userID_75  userID_78  userID_127  userID_170  userID_175  \\\n",
       "266989       3          0          0           0           0           0   \n",
       "158068       4          0          0           0           0           0   \n",
       "552454       2          0          0           0           0           0   \n",
       "658846       3          0          0           0           0           0   \n",
       "432255       1          0          0           0           0           0   \n",
       "\n",
       "        userID_190  userID_267  userID_325  userID_383  ...  date_hour_14  \\\n",
       "266989           0           0           0           0  ...             0   \n",
       "158068           0           0           0           0  ...             0   \n",
       "552454           0           0           0           0  ...             0   \n",
       "658846           0           0           0           0  ...             0   \n",
       "432255           0           0           0           0  ...             0   \n",
       "\n",
       "        date_hour_15  date_hour_16  date_hour_17  date_hour_18  date_hour_19  \\\n",
       "266989             0             0             0             0             0   \n",
       "158068             0             0             0             0             1   \n",
       "552454             0             0             0             0             0   \n",
       "658846             0             0             0             0             0   \n",
       "432255             0             1             0             0             0   \n",
       "\n",
       "        date_hour_20  date_hour_21  date_hour_22  date_hour_23  \n",
       "266989             0             0             0             0  \n",
       "158068             0             0             0             0  \n",
       "552454             0             0             0             0  \n",
       "658846             0             0             0             0  \n",
       "432255             0             0             0             0  \n",
       "\n",
       "[5 rows x 11111 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_df_to_flatten(df, columns=[\"userID\", \"movieID\", \"date_hour\"]):\n",
    "    return pd.get_dummies(df, columns=columns).astype(int)\n",
    "\n",
    "# Apply one-hot encoding to 'userID', 'movieID', and 'date_hour'\n",
    "train_sparse_df = convert_df_to_flatten(train_df)\n",
    "test_sparse_df = convert_df_to_flatten(test_df)\n",
    "\n",
    "# Display the resulting sparse DataFrame\n",
    "train_sparse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that flatten is successful (columns = users + movies + context + target)\n",
    "assert train_sparse_df.shape[1] == train_df[\"userID\"].nunique() + train_df[\"movieID\"].nunique() + train_df[\"date_hour\"].nunique() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that we need to do is prepare the data to be consumed by the [LibFM](http://www.libfm.org/libfm-1.42.manual.pdf) python library. The data format being used by Libfm expects the following format:\n",
    "\n",
    "![Libfm_format](img/libfm_text_format.png)\n",
    "\n",
    "The first column states the target of each of the three case: i.e. rating=4 for the first case, rating=2 for the second and rating=-1 for the third. After the target, each line contains the non-zero elements of $x$, where an entry like 0:1.5 reads $x_0 = 1.5$ and 3:-7.9 means $x_3 = −7.9$, etc. That means the left side of INDEX:VALUE states the index within $x$ whereas the right side states the value of $x_\\text{INDEX}$, i.e. $x_\\text{INDEX}$ = VALUE.\n",
    "\n",
    "The above example would equal to the following matrix representations:\n",
    "$$\n",
    "X = \\begin{pmatrix}\n",
    "1.5 & 0.0 & 0.0 & -7.9 & 0.0 & 0.0 & 0.0 \\\\\n",
    "0.0 & 10^{-5} & 0.0 & 2.0 & 0.0 & 0.0 & 0.0 \\\\\n",
    "0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 \\\\\n",
    "\\end{pmatrix},\n",
    "\\quad\n",
    "y = \\begin{pmatrix}\n",
    "4 \\\\\n",
    "2 \\\\\n",
    "-1 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_to_libfm_format(df):\n",
    "    \"\"\" Converts a pandas data frame to the expected data format of the libFM library \"\"\"\n",
    "    \n",
    "    # Initialize an empty list to store each row in the required format\n",
    "    fm_format_data = []\n",
    "    \n",
    "    # Iterate through each row in the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        # Start the line with the rating as the target value\n",
    "        line = [str(row['rating'])]\n",
    "        \n",
    "        # Iterate over each feature column (except 'rating') and find non-zero entries\n",
    "        for j, (col, value) in enumerate(row.items()):\n",
    "            if col != 'rating' and value != 0:  # Only include non-zero entries\n",
    "                line.append(f\"{j-1}:{value}\")   # Adjusting index by -1 to account for \"rating\" column\n",
    "        \n",
    "        # Join the line elements with spaces and add to the output list\n",
    "        fm_format_data.append(\" \".join(line))\n",
    "    \n",
    "    return fm_format_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 681:1 7756:1 11098:1\n",
      "4 392:1 3572:1 11105:1\n",
      "2 1312:1 4043:1 11091:1\n",
      "3 1574:1 4127:1 11087:1\n",
      "1 1019:1 5444:1 11102:1\n"
     ]
    }
   ],
   "source": [
    "# Generate the libFM formatted data\n",
    "fm_train_df = convert_df_to_libfm_format(train_sparse_df)\n",
    "fm_test_df = convert_df_to_libfm_format(test_sparse_df)\n",
    "\n",
    "# Print the first few lines to verify\n",
    "for line in fm_train_df[:5]:\n",
    "    print(line)\n",
    "    \n",
    "# NOTE: Takes about ~10min to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment if interested to perform sanity checks based on above output and libFM data expectations\n",
    "# train_sparse_df.drop('rating', axis=1).iloc[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train data as train.libfm\n",
    "with open(\"train.libfm\", \"w\") as train_file:\n",
    "    for line in fm_train_df:\n",
    "        train_file.write(line + \"\\n\")\n",
    "\n",
    "# Save test data as test.libfm\n",
    "with open(\"test.libfm\", \"w\") as test_file:\n",
    "    for line in fm_test_df:\n",
    "        test_file.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.4.4\n",
      "  Author:  Steffen Rendle, srendle@libfm.org\n",
      "  WWW:     http://www.libfm.org/\n",
      "This program comes with ABSOLUTELY NO WARRANTY; for details see license.txt.\n",
      "This is free software, and you are welcome to redistribute it under certain\n",
      "conditions; for details see license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "-cache_size     cache size for data storage (only applicable if data is\n",
      "                in binary format), default=infty\n",
      "-dim            'k0,k1,k2': k0=use bias, k1=use 1-way interactions,\n",
      "                k2=dim of 2-way interactions; default=1,1,8\n",
      "-help           this screen\n",
      "-init_stdev     stdev for initialization of 2-way factors; default=0.1\n",
      "-iter           number of iterations; default=100\n",
      "-learn_rate     learn_rate for SGD; default=0.1\n",
      "-load_model     filename for reading the FM model\n",
      "-meta           filename for meta information about data set\n",
      "-method         learning method (SGD, SGDA, ALS, MCMC); default=MCMC\n",
      "-out            filename for output\n",
      "-regular        'r0,r1,r2' for SGD and ALS: r0=bias regularization,\n",
      "                r1=1-way regularization, r2=2-way regularization\n",
      "-relation       BS: filenames for the relations, default=''\n",
      "-rlog           write measurements within iterations to a file;\n",
      "                default=''\n",
      "-save_model     filename for writing the FM model\n",
      "-seed           integer value, default=None\n",
      "-task           r=regression, c=binary classification [MANDATORY]\n",
      "-test           filename for test data [MANDATORY]\n",
      "-train          filename for training data [MANDATORY]\n",
      "-validation     filename for validation data (only for SGDA)\n",
      "-verbosity      how much infos to print; default=0\n"
     ]
    }
   ],
   "source": [
    "# Explore usage of the libFM parameters\n",
    "!./libfm/bin/libFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important parameter here is the **\"dim\" parameter** representing $k_0$, $k_1$ and $k_2$ which controls the dimensionality of the factorization machine model.\n",
    "\n",
    "Let's recall our Loss function and how the $k$ parameters are connected:\n",
    "$$\n",
    "\\hat{y}(\\mathbf{x}_i) = w_0 + \\sum_{f=1}^{p} w_f \\cdot x_{if} + \\sum_{f=1}^{p} \\sum_{g=f+1}^{p} x_{if} \\cdot x_{ig} \\left( \\sum_{k=1}^{K} v_{fk} \\cdot v_{gk} \\right)\n",
    "$$\n",
    "\n",
    "1. **$w_0$** is the global bias term, controlled by $k_0$.\n",
    "   - When $k_0 = 1$, $w_0$ is included. This parameter represents an overall bias for all predictions (the baseline level).\n",
    "   - When $k_0 = 0$, the bias term is excluded from the model.\n",
    "\n",
    "2. **$\\sum_{f=1}^{p} w_f \\cdot x_{if}$** represents one-way (linear) interactions for each feature, controlled by $k_1$.\n",
    "   - If $k_1 = 1$, each feature $x_{if}$ has a weight $w_f$, and their linear contributions are added to the prediction.\n",
    "   - If $k_1 = 0$, these linear terms are excluded, and the model focuses only on interactions between features.\n",
    "\n",
    "3. **$\\sum_{f=1}^{p} \\sum_{g=f+1}^{p} x_{if} \\cdot x_{ig} \\left( \\sum_{k=1}^{K} v_{fk} \\cdot v_{gk} \\right)$** represents two-way (pairwise) interactions between features, controlled by $k_2$, where:\n",
    "   - $v_{fk}$ and $v_{gk}$ are latent factors that capture hidden relationships between features.\n",
    "   - $k_2$ (the dimensionality of the latent factors) controls how complex or nuanced these interactions can be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of **$k_2$** depends on the complexity of your data and the capacity of the model you want to build:\n",
    "\n",
    "- Small values of $k_2$ (e.g., 2-10):\n",
    "  - Less complex interactions: Good for smaller or simpler datasets.\n",
    "  - Less computationally expensive: Reduces memory and computational requirements, making the model faster to train.\n",
    "\n",
    "- Larger values of $k_2$ (e.g., 20-100):\n",
    "  - More complex interactions: Allows the model to capture more detailed and nuanced interactions between features.\n",
    "  - More computationally intensive: Requires more memory and may take longer to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.4.4\n",
      "  Author:  Steffen Rendle, srendle@libfm.org\n",
      "  WWW:     http://www.libfm.org/\n",
      "This program comes with ABSOLUTELY NO WARRANTY; for details see license.txt.\n",
      "This is free software, and you are welcome to redistribute it under certain\n",
      "conditions; for details see license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "Loading train...\t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=240000\tnum_values=720000\tnum_features=11110\tmin_target=0\tmax_target=5\n",
      "Loading test... \t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=60000\tnum_values=180000\tnum_features=8906\tmin_target=0\tmax_target=5\n",
      "#relations: 0\n",
      "Loading meta data...\t\n",
      "#Iter=  0\tTrain=1.01875\tTest=1.06367\n",
      "#Iter=  1\tTrain=0.913931\tTest=1.05874\n",
      "#Iter=  2\tTrain=0.876879\tTest=1.06844\n",
      "#Iter=  3\tTrain=0.858092\tTest=1.08006\n",
      "#Iter=  4\tTrain=0.847626\tTest=1.09513\n",
      "#Iter=  5\tTrain=0.840836\tTest=1.10753\n",
      "#Iter=  6\tTrain=0.837865\tTest=1.11934\n",
      "#Iter=  7\tTrain=0.837391\tTest=1.1312\n",
      "#Iter=  8\tTrain=0.835406\tTest=1.14273\n",
      "#Iter=  9\tTrain=0.834596\tTest=1.15229\n",
      "#Iter= 10\tTrain=0.833458\tTest=1.15953\n",
      "#Iter= 11\tTrain=0.832274\tTest=1.17003\n",
      "#Iter= 12\tTrain=0.83132\tTest=1.17541\n",
      "#Iter= 13\tTrain=0.831216\tTest=1.1829\n",
      "#Iter= 14\tTrain=0.83051\tTest=1.18861\n",
      "#Iter= 15\tTrain=0.829826\tTest=1.19229\n",
      "#Iter= 16\tTrain=0.829292\tTest=1.19613\n",
      "#Iter= 17\tTrain=0.829248\tTest=1.20154\n",
      "#Iter= 18\tTrain=0.829285\tTest=1.20333\n",
      "#Iter= 19\tTrain=0.830713\tTest=1.20481\n",
      "#Iter= 20\tTrain=0.829334\tTest=1.20681\n",
      "#Iter= 21\tTrain=0.827903\tTest=1.20929\n",
      "#Iter= 22\tTrain=0.827633\tTest=1.21121\n",
      "#Iter= 23\tTrain=0.828194\tTest=1.21263\n",
      "#Iter= 24\tTrain=0.82776\tTest=1.21452\n",
      "#Iter= 25\tTrain=0.827854\tTest=1.2152\n",
      "#Iter= 26\tTrain=0.827438\tTest=1.21664\n",
      "#Iter= 27\tTrain=0.826889\tTest=1.21723\n",
      "#Iter= 28\tTrain=0.825799\tTest=1.21861\n",
      "#Iter= 29\tTrain=0.825768\tTest=1.21956\n",
      "#Iter= 30\tTrain=0.826373\tTest=1.22108\n",
      "#Iter= 31\tTrain=0.825442\tTest=1.22125\n",
      "#Iter= 32\tTrain=0.825339\tTest=1.22246\n",
      "#Iter= 33\tTrain=0.825497\tTest=1.22352\n",
      "#Iter= 34\tTrain=0.825376\tTest=1.22442\n",
      "#Iter= 35\tTrain=0.824379\tTest=1.22517\n",
      "#Iter= 36\tTrain=0.823458\tTest=1.22639\n",
      "#Iter= 37\tTrain=0.822918\tTest=1.22715\n",
      "#Iter= 38\tTrain=0.823327\tTest=1.22796\n",
      "#Iter= 39\tTrain=0.823155\tTest=1.22844\n",
      "#Iter= 40\tTrain=0.824059\tTest=1.22916\n",
      "#Iter= 41\tTrain=0.822115\tTest=1.22933\n",
      "#Iter= 42\tTrain=0.822489\tTest=1.22994\n",
      "#Iter= 43\tTrain=0.82278\tTest=1.23043\n",
      "#Iter= 44\tTrain=0.822667\tTest=1.23062\n",
      "#Iter= 45\tTrain=0.822723\tTest=1.23126\n",
      "#Iter= 46\tTrain=0.821793\tTest=1.23146\n",
      "#Iter= 47\tTrain=0.82208\tTest=1.23257\n",
      "#Iter= 48\tTrain=0.821057\tTest=1.23358\n",
      "#Iter= 49\tTrain=0.820664\tTest=1.23375\n",
      "#Iter= 50\tTrain=0.821499\tTest=1.23406\n",
      "#Iter= 51\tTrain=0.820458\tTest=1.23445\n",
      "#Iter= 52\tTrain=0.820526\tTest=1.23434\n",
      "#Iter= 53\tTrain=0.820157\tTest=1.2352\n",
      "#Iter= 54\tTrain=0.820173\tTest=1.23546\n",
      "#Iter= 55\tTrain=0.819273\tTest=1.23559\n",
      "#Iter= 56\tTrain=0.818533\tTest=1.23604\n",
      "#Iter= 57\tTrain=0.817699\tTest=1.23681\n",
      "#Iter= 58\tTrain=0.816276\tTest=1.23714\n",
      "#Iter= 59\tTrain=0.815106\tTest=1.23753\n",
      "#Iter= 60\tTrain=0.813712\tTest=1.2378\n",
      "#Iter= 61\tTrain=0.810815\tTest=1.23786\n",
      "#Iter= 62\tTrain=0.807821\tTest=1.2382\n",
      "#Iter= 63\tTrain=0.803166\tTest=1.23848\n",
      "#Iter= 64\tTrain=0.79912\tTest=1.23908\n",
      "#Iter= 65\tTrain=0.79569\tTest=1.23888\n",
      "#Iter= 66\tTrain=0.791977\tTest=1.2389\n",
      "#Iter= 67\tTrain=0.788587\tTest=1.23907\n",
      "#Iter= 68\tTrain=0.787204\tTest=1.23916\n",
      "#Iter= 69\tTrain=0.784193\tTest=1.23915\n",
      "#Iter= 70\tTrain=0.781796\tTest=1.23854\n",
      "#Iter= 71\tTrain=0.779952\tTest=1.2383\n",
      "#Iter= 72\tTrain=0.778467\tTest=1.23791\n",
      "#Iter= 73\tTrain=0.778441\tTest=1.2375\n",
      "#Iter= 74\tTrain=0.777268\tTest=1.23714\n",
      "#Iter= 75\tTrain=0.776865\tTest=1.23652\n",
      "#Iter= 76\tTrain=0.776035\tTest=1.23617\n",
      "#Iter= 77\tTrain=0.775382\tTest=1.23562\n",
      "#Iter= 78\tTrain=0.774877\tTest=1.23532\n",
      "#Iter= 79\tTrain=0.773813\tTest=1.23484\n",
      "#Iter= 80\tTrain=0.772658\tTest=1.23454\n",
      "#Iter= 81\tTrain=0.771727\tTest=1.23427\n",
      "#Iter= 82\tTrain=0.771164\tTest=1.23391\n",
      "#Iter= 83\tTrain=0.770695\tTest=1.23349\n",
      "#Iter= 84\tTrain=0.769442\tTest=1.23343\n",
      "#Iter= 85\tTrain=0.769114\tTest=1.23288\n",
      "#Iter= 86\tTrain=0.768057\tTest=1.2324\n",
      "#Iter= 87\tTrain=0.767687\tTest=1.23194\n",
      "#Iter= 88\tTrain=0.767145\tTest=1.23139\n",
      "#Iter= 89\tTrain=0.766135\tTest=1.23103\n",
      "#Iter= 90\tTrain=0.7659\tTest=1.23091\n",
      "#Iter= 91\tTrain=0.765629\tTest=1.23036\n",
      "#Iter= 92\tTrain=0.764884\tTest=1.22978\n",
      "#Iter= 93\tTrain=0.765303\tTest=1.22969\n",
      "#Iter= 94\tTrain=0.764074\tTest=1.22953\n",
      "#Iter= 95\tTrain=0.763502\tTest=1.22919\n",
      "#Iter= 96\tTrain=0.763627\tTest=1.22896\n",
      "#Iter= 97\tTrain=0.764435\tTest=1.22885\n",
      "#Iter= 98\tTrain=0.763283\tTest=1.22844\n",
      "#Iter= 99\tTrain=0.76305\tTest=1.22823\n",
      "#Iter=100\tTrain=0.762739\tTest=1.22793\n",
      "#Iter=101\tTrain=0.76171\tTest=1.22767\n",
      "#Iter=102\tTrain=0.761974\tTest=1.22777\n",
      "#Iter=103\tTrain=0.761147\tTest=1.22754\n",
      "#Iter=104\tTrain=0.760121\tTest=1.22725\n",
      "#Iter=105\tTrain=0.760405\tTest=1.22712\n",
      "#Iter=106\tTrain=0.760204\tTest=1.22687\n",
      "#Iter=107\tTrain=0.760465\tTest=1.22687\n",
      "#Iter=108\tTrain=0.760006\tTest=1.22654\n",
      "#Iter=109\tTrain=0.760015\tTest=1.22645\n",
      "#Iter=110\tTrain=0.759343\tTest=1.22663\n",
      "#Iter=111\tTrain=0.759339\tTest=1.22676\n",
      "#Iter=112\tTrain=0.760159\tTest=1.22648\n",
      "#Iter=113\tTrain=0.760053\tTest=1.2263\n",
      "#Iter=114\tTrain=0.759924\tTest=1.2262\n",
      "#Iter=115\tTrain=0.759838\tTest=1.22603\n",
      "#Iter=116\tTrain=0.75913\tTest=1.22595\n",
      "#Iter=117\tTrain=0.760041\tTest=1.2259\n",
      "#Iter=118\tTrain=0.759462\tTest=1.22563\n",
      "#Iter=119\tTrain=0.758812\tTest=1.22536\n",
      "#Iter=120\tTrain=0.757887\tTest=1.22524\n",
      "#Iter=121\tTrain=0.757982\tTest=1.22516\n",
      "#Iter=122\tTrain=0.757832\tTest=1.22497\n",
      "#Iter=123\tTrain=0.757584\tTest=1.22493\n",
      "#Iter=124\tTrain=0.756446\tTest=1.22454\n",
      "#Iter=125\tTrain=0.755933\tTest=1.22435\n",
      "#Iter=126\tTrain=0.755359\tTest=1.22431\n",
      "#Iter=127\tTrain=0.756314\tTest=1.22435\n",
      "#Iter=128\tTrain=0.755653\tTest=1.22432\n",
      "#Iter=129\tTrain=0.755635\tTest=1.22438\n",
      "#Iter=130\tTrain=0.755449\tTest=1.22457\n",
      "#Iter=131\tTrain=0.754438\tTest=1.22447\n",
      "#Iter=132\tTrain=0.753814\tTest=1.22438\n",
      "#Iter=133\tTrain=0.753499\tTest=1.22443\n",
      "#Iter=134\tTrain=0.753004\tTest=1.22454\n",
      "#Iter=135\tTrain=0.752818\tTest=1.22471\n",
      "#Iter=136\tTrain=0.752995\tTest=1.22461\n",
      "#Iter=137\tTrain=0.752969\tTest=1.22473\n",
      "#Iter=138\tTrain=0.751428\tTest=1.22477\n",
      "#Iter=139\tTrain=0.751371\tTest=1.22478\n",
      "#Iter=140\tTrain=0.752076\tTest=1.22479\n",
      "#Iter=141\tTrain=0.750901\tTest=1.22478\n",
      "#Iter=142\tTrain=0.751296\tTest=1.225\n",
      "#Iter=143\tTrain=0.751091\tTest=1.22497\n",
      "#Iter=144\tTrain=0.75052\tTest=1.225\n",
      "#Iter=145\tTrain=0.750075\tTest=1.22505\n",
      "#Iter=146\tTrain=0.750382\tTest=1.22508\n",
      "#Iter=147\tTrain=0.749264\tTest=1.22502\n",
      "#Iter=148\tTrain=0.748616\tTest=1.22503\n",
      "#Iter=149\tTrain=0.748811\tTest=1.22509\n",
      "#Iter=150\tTrain=0.748744\tTest=1.2252\n",
      "#Iter=151\tTrain=0.746909\tTest=1.22516\n",
      "#Iter=152\tTrain=0.747489\tTest=1.22513\n",
      "#Iter=153\tTrain=0.747035\tTest=1.22511\n",
      "#Iter=154\tTrain=0.747119\tTest=1.2251\n",
      "#Iter=155\tTrain=0.74652\tTest=1.22493\n",
      "#Iter=156\tTrain=0.746627\tTest=1.22477\n",
      "#Iter=157\tTrain=0.746413\tTest=1.2248\n",
      "#Iter=158\tTrain=0.746167\tTest=1.22495\n",
      "#Iter=159\tTrain=0.744717\tTest=1.22508\n",
      "#Iter=160\tTrain=0.74488\tTest=1.22526\n",
      "#Iter=161\tTrain=0.744366\tTest=1.22528\n",
      "#Iter=162\tTrain=0.743476\tTest=1.22527\n",
      "#Iter=163\tTrain=0.743472\tTest=1.22532\n",
      "#Iter=164\tTrain=0.742744\tTest=1.22528\n",
      "#Iter=165\tTrain=0.743085\tTest=1.22535\n",
      "#Iter=166\tTrain=0.742444\tTest=1.22535\n",
      "#Iter=167\tTrain=0.7416\tTest=1.22536\n",
      "#Iter=168\tTrain=0.741267\tTest=1.22544\n",
      "#Iter=169\tTrain=0.740552\tTest=1.22548\n",
      "#Iter=170\tTrain=0.741116\tTest=1.22541\n",
      "#Iter=171\tTrain=0.739109\tTest=1.22568\n",
      "#Iter=172\tTrain=0.738928\tTest=1.2257\n",
      "#Iter=173\tTrain=0.739089\tTest=1.22588\n",
      "#Iter=174\tTrain=0.737866\tTest=1.22588\n",
      "#Iter=175\tTrain=0.737823\tTest=1.22599\n",
      "#Iter=176\tTrain=0.736774\tTest=1.22597\n",
      "#Iter=177\tTrain=0.737616\tTest=1.22603\n",
      "#Iter=178\tTrain=0.737859\tTest=1.22606\n",
      "#Iter=179\tTrain=0.737144\tTest=1.22605\n",
      "#Iter=180\tTrain=0.735902\tTest=1.22597\n",
      "#Iter=181\tTrain=0.73593\tTest=1.22597\n",
      "#Iter=182\tTrain=0.73601\tTest=1.22595\n",
      "#Iter=183\tTrain=0.734577\tTest=1.22592\n",
      "#Iter=184\tTrain=0.733586\tTest=1.2259\n",
      "#Iter=185\tTrain=0.73453\tTest=1.22591\n",
      "#Iter=186\tTrain=0.73442\tTest=1.2259\n",
      "#Iter=187\tTrain=0.733611\tTest=1.2257\n",
      "#Iter=188\tTrain=0.733836\tTest=1.22559\n",
      "#Iter=189\tTrain=0.733424\tTest=1.22568\n",
      "#Iter=190\tTrain=0.733414\tTest=1.22569\n",
      "#Iter=191\tTrain=0.732725\tTest=1.22566\n",
      "#Iter=192\tTrain=0.733369\tTest=1.22577\n",
      "#Iter=193\tTrain=0.733434\tTest=1.22582\n",
      "#Iter=194\tTrain=0.733512\tTest=1.22578\n",
      "#Iter=195\tTrain=0.732549\tTest=1.22583\n",
      "#Iter=196\tTrain=0.732995\tTest=1.22583\n",
      "#Iter=197\tTrain=0.732799\tTest=1.22567\n",
      "#Iter=198\tTrain=0.73265\tTest=1.22563\n",
      "#Iter=199\tTrain=0.731024\tTest=1.2256\n"
     ]
    }
   ],
   "source": [
    "# Train the Contextual Awareness recommender system and validating on the test set.\n",
    "!./libfm/bin/libFM -task r -train train.libfm -test test.libfm -seed 42 -dim \"1,1,10\" -iter 200\n",
    "\n",
    "# Parameters:\n",
    "# 1. -dim: 1 (Train global bias), 1 (Use 1-way interactions), 10 (Use 10-latent factor columns)\n",
    "# 2. -iter: 200 (Perform 200 iterations for training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the the **RMSE** for the test set is: **1.2256**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Factorised Machines without Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating_threshold = 1.0\n",
      "exclude_unknowns = False\n",
      "---\n",
      "Training data:\n",
      "Number of users = 2113\n",
      "Number of items = 8973\n",
      "Number of ratings = 240000\n",
      "Max rating = 23.0\n",
      "Min rating = 0.0\n",
      "Global mean = 12.1\n",
      "---\n",
      "Test data:\n",
      "Number of users = 2113\n",
      "Number of items = 9220\n",
      "Number of ratings = 60000\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 247\n",
      "---\n",
      "Total users = 2113\n",
      "Total items = 9220\n"
     ]
    }
   ],
   "source": [
    "VERBOSE = True\n",
    "SEED = 42\n",
    "\n",
    "# 1. Define the Matrix Factorisation model\n",
    "mf = cornac.models.MF(\n",
    "    k=10, \n",
    "    max_iter=20, \n",
    "    learning_rate=0.01, \n",
    "    lambda_reg=0.02, \n",
    "    use_bias=True,\n",
    "    verbose=VERBOSE, \n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "# 2. Define the evaluation method of the model (i.e. train-test split)\n",
    "eval_method = cornac.eval_methods.BaseMethod.from_splits(\n",
    "    train_data=list(train_df.itertuples(index=False)), \n",
    "    test_data=list(test_df.itertuples(index=False)),\n",
    "    exclude_unknowns=False, \n",
    "    verbose=VERBOSE,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MF] Training started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 287.64it/s, loss=3348350.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished!\n",
      "\n",
      "[MF] Evaluation started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rating: 100%|██████████| 60000/60000 [00:00<00:00, 208216.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |   RMSE | Train (s) | Test (s)\n",
      "-- + ------ + --------- + --------\n",
      "MF | 7.3402 |    0.4122 |   0.2982\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the RMSE of the Matrix factorisation model\n",
    "test_result, _ = eval_method.evaluate(\n",
    "    model=mf, \n",
    "    metrics=[cornac.metrics.RMSE()],\n",
    "    user_based=False,\n",
    ")\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the the **RMSE** for the test set is: **7.3402**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** We can see that the **Contextual Model (RMSE = 1.2256)** *outperformed* the **Non-Contextual Model (RMSE = 7.3402)**. <br>\n",
    "In other words, it provided more **accurate** and **relevant** predictions of each user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three primary ways in which context-aware recommendations are performed.\n",
    "\n",
    "* **Pre-filtering:** \n",
    "The problem is reduced to a 2-dimensional collaborative filtering problem by filtering the w-dimensional cube to a 2-dimensional ratings matrix before applying the collaborative filtering algorithm.\n",
    "\n",
    "* **Post-filtering:** \n",
    "The context is ignored during the first phase of collaborative filtering. Subsequently, the results are adjusted with the use of a predictive model that regulates the relative importance of context. \n",
    "\n",
    "* **Contextual Modelling:**\n",
    "Finally, a recent approach is to incorporate the context directly into the model by treating it as a $w$-dimensional prediction problem. Generalizations of matrix factorization and linear regression models have been proposed in this setting. This approach is computationally intensive, but it is a generic approach with the best potential when a large amount of data is available."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
